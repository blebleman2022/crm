#!/usr/bin/env python3
"""
æ•°æ®åº“å¥åº·ç›‘æ§è„šæœ¬
ç”¨äºè¯„ä¼°æ˜¯å¦éœ€è¦ä»SQLiteè¿ç§»åˆ°MySQL
"""
import sqlite3
import os
from datetime import datetime, timedelta

DB_PATH = 'instance/edu_crm.db'

# å‘Šè­¦é˜ˆå€¼
THRESHOLDS = {
    'db_size_warning': 1 * 1024 * 1024 * 1024,  # 1GB
    'db_size_critical': 5 * 1024 * 1024 * 1024,  # 5GB
    'table_rows_warning': 100000,  # 10ä¸‡æ¡
    'table_rows_critical': 1000000,  # 100ä¸‡æ¡
    'query_time_warning': 0.5,  # 500ms
    'query_time_critical': 1.0,  # 1ç§’
}

def get_db_size():
    """è·å–æ•°æ®åº“æ–‡ä»¶å¤§å°"""
    return os.path.getsize(DB_PATH)

def format_size(bytes_size):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if bytes_size < 1024.0:
            return f"{bytes_size:.2f} {unit}"
        bytes_size /= 1024.0
    return f"{bytes_size:.2f} TB"

def get_table_stats(conn):
    """è·å–å„è¡¨ç»Ÿè®¡ä¿¡æ¯"""
    cursor = conn.cursor()
    
    # è·å–æ‰€æœ‰è¡¨
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'")
    tables = [row[0] for row in cursor.fetchall()]
    
    stats = []
    for table in tables:
        cursor.execute(f"SELECT COUNT(*) FROM {table}")
        count = cursor.fetchone()[0]
        stats.append({
            'table': table,
            'rows': count
        })
    
    return sorted(stats, key=lambda x: x['rows'], reverse=True)

def estimate_growth_rate(conn):
    """ä¼°ç®—æ•°æ®å¢é•¿ç‡"""
    cursor = conn.cursor()
    
    # è·å–æœ€è¿‘30å¤©çš„çº¿ç´¢å¢é•¿
    cursor.execute("""
        SELECT COUNT(*) 
        FROM leads 
        WHERE created_at >= date('now', '-30 days')
    """)
    leads_30d = cursor.fetchone()[0]
    
    # è·å–æœ€è¿‘30å¤©çš„å®¢æˆ·å¢é•¿
    cursor.execute("""
        SELECT COUNT(*) 
        FROM customers 
        WHERE created_at >= date('now', '-30 days')
    """)
    customers_30d = cursor.fetchone()[0]
    
    return {
        'leads_per_month': leads_30d,
        'customers_per_month': customers_30d,
        'total_per_month': leads_30d + customers_30d
    }

def predict_future_size(current_size, growth_rate, months):
    """é¢„æµ‹æœªæ¥æ•°æ®åº“å¤§å°"""
    # å‡è®¾æ¯æ¡è®°å½•å¹³å‡2KB
    avg_record_size = 2 * 1024
    monthly_growth = growth_rate['total_per_month'] * avg_record_size
    future_size = current_size + (monthly_growth * months)
    return future_size

def check_query_performance(conn):
    """æ£€æŸ¥æŸ¥è¯¢æ€§èƒ½"""
    import time
    cursor = conn.cursor()
    
    # æµ‹è¯•å‡ ä¸ªå¸¸è§æŸ¥è¯¢
    queries = [
        ("SELECT COUNT(*) FROM leads", "çº¿ç´¢æ€»æ•°æŸ¥è¯¢"),
        ("SELECT * FROM leads ORDER BY created_at DESC LIMIT 20", "æœ€æ–°çº¿ç´¢æŸ¥è¯¢"),
        ("SELECT l.*, u.username FROM leads l JOIN users u ON l.sales_user_id = u.id LIMIT 20", "çº¿ç´¢å…³è”æŸ¥è¯¢"),
    ]
    
    results = []
    for sql, desc in queries:
        start = time.time()
        cursor.execute(sql)
        cursor.fetchall()
        elapsed = time.time() - start
        
        results.append({
            'query': desc,
            'time': elapsed,
            'status': 'OK' if elapsed < THRESHOLDS['query_time_warning'] else 
                     'WARNING' if elapsed < THRESHOLDS['query_time_critical'] else 'CRITICAL'
        })
    
    return results

def generate_report():
    """ç”Ÿæˆç›‘æ§æŠ¥å‘Š"""
    conn = sqlite3.connect(DB_PATH)
    
    print("=" * 80)
    print("EduConnect CRM æ•°æ®åº“å¥åº·ç›‘æ§æŠ¥å‘Š")
    print("=" * 80)
    print(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # 1. æ•°æ®åº“å¤§å°
    print("ã€1ã€‘æ•°æ®åº“å¤§å°")
    print("-" * 80)
    db_size = get_db_size()
    print(f"  å½“å‰å¤§å°: {format_size(db_size)}")
    
    if db_size > THRESHOLDS['db_size_critical']:
        print(f"  çŠ¶æ€: ğŸ”´ CRITICAL - è¶…è¿‡5GBï¼Œå¼ºçƒˆå»ºè®®è¿ç§»åˆ°MySQL")
    elif db_size > THRESHOLDS['db_size_warning']:
        print(f"  çŠ¶æ€: ğŸŸ¡ WARNING - è¶…è¿‡1GBï¼Œå»ºè®®å¼€å§‹å‡†å¤‡è¿ç§»æ–¹æ¡ˆ")
    else:
        print(f"  çŠ¶æ€: ğŸŸ¢ OK - SQLiteå®Œå…¨æ»¡è¶³éœ€æ±‚")
    
    # 2. è¡¨æ•°æ®ç»Ÿè®¡
    print("\nã€2ã€‘è¡¨æ•°æ®ç»Ÿè®¡")
    print("-" * 80)
    table_stats = get_table_stats(conn)
    
    total_rows = sum(stat['rows'] for stat in table_stats)
    print(f"  æ€»è®°å½•æ•°: {total_rows:,}")
    print(f"\n  å„è¡¨è®°å½•æ•°:")
    
    for stat in table_stats:
        status = ""
        if stat['rows'] > THRESHOLDS['table_rows_critical']:
            status = "ğŸ”´ CRITICAL"
        elif stat['rows'] > THRESHOLDS['table_rows_warning']:
            status = "ğŸŸ¡ WARNING"
        else:
            status = "ğŸŸ¢ OK"
        
        print(f"    {stat['table']:30s} : {stat['rows']:8,} æ¡  {status}")
    
    # 3. å¢é•¿ç‡åˆ†æ
    print("\nã€3ã€‘æ•°æ®å¢é•¿åˆ†æ")
    print("-" * 80)
    growth = estimate_growth_rate(conn)
    print(f"  æœ€è¿‘30å¤©æ–°å¢çº¿ç´¢: {growth['leads_per_month']} æ¡")
    print(f"  æœ€è¿‘30å¤©æ–°å¢å®¢æˆ·: {growth['customers_per_month']} æ¡")
    print(f"  æœˆå‡å¢é•¿: {growth['total_per_month']} æ¡è®°å½•")
    
    # 4. æœªæ¥é¢„æµ‹
    print("\nã€4ã€‘æœªæ¥å®¹é‡é¢„æµ‹")
    print("-" * 80)
    for months in [6, 12, 24, 36]:
        future_size = predict_future_size(db_size, growth, months)
        print(f"  {months:2d}ä¸ªæœˆåé¢„è®¡: {format_size(future_size)}")
    
    # 5. æŸ¥è¯¢æ€§èƒ½
    print("\nã€5ã€‘æŸ¥è¯¢æ€§èƒ½æµ‹è¯•")
    print("-" * 80)
    perf_results = check_query_performance(conn)
    
    for result in perf_results:
        status_icon = {
            'OK': 'ğŸŸ¢',
            'WARNING': 'ğŸŸ¡',
            'CRITICAL': 'ğŸ”´'
        }[result['status']]
        
        print(f"  {status_icon} {result['query']:30s} : {result['time']*1000:.2f}ms")
    
    # 6. è¿ç§»å»ºè®®
    print("\nã€6ã€‘è¿ç§»å»ºè®®")
    print("-" * 80)
    
    # è®¡ç®—è¿ç§»è¯„åˆ†
    migration_score = 0
    reasons = []
    
    if db_size > THRESHOLDS['db_size_critical']:
        migration_score += 50
        reasons.append("æ•°æ®åº“å¤§å°è¶…è¿‡5GB")
    elif db_size > THRESHOLDS['db_size_warning']:
        migration_score += 20
        reasons.append("æ•°æ®åº“å¤§å°è¶…è¿‡1GB")
    
    for stat in table_stats:
        if stat['rows'] > THRESHOLDS['table_rows_critical']:
            migration_score += 30
            reasons.append(f"{stat['table']}è¡¨è®°å½•æ•°è¶…è¿‡100ä¸‡")
            break
        elif stat['rows'] > THRESHOLDS['table_rows_warning']:
            migration_score += 10
            reasons.append(f"{stat['table']}è¡¨è®°å½•æ•°è¶…è¿‡10ä¸‡")
            break
    
    for result in perf_results:
        if result['status'] == 'CRITICAL':
            migration_score += 30
            reasons.append(f"æŸ¥è¯¢æ€§èƒ½ä¸¥é‡ä¸‹é™ï¼ˆ{result['query']}ï¼‰")
            break
        elif result['status'] == 'WARNING':
            migration_score += 10
            reasons.append(f"æŸ¥è¯¢æ€§èƒ½å¼€å§‹ä¸‹é™ï¼ˆ{result['query']}ï¼‰")
            break
    
    # é¢„æµ‹6ä¸ªæœˆåå¤§å°
    future_6m = predict_future_size(db_size, growth, 6)
    if future_6m > THRESHOLDS['db_size_warning']:
        migration_score += 15
        reasons.append("6ä¸ªæœˆåé¢„è®¡è¶…è¿‡1GB")
    
    # ç»™å‡ºå»ºè®®
    print(f"  è¿ç§»è¯„åˆ†: {migration_score}/100")
    print()
    
    if migration_score >= 70:
        print("  ğŸ”´ å»ºè®®: ç«‹å³å¼€å§‹è¿ç§»åˆ°MySQL")
        print("  ç†ç”±:")
        for reason in reasons:
            print(f"    - {reason}")
    elif migration_score >= 40:
        print("  ğŸŸ¡ å»ºè®®: å¼€å§‹å‡†å¤‡MySQLè¿ç§»æ–¹æ¡ˆ")
        print("  ç†ç”±:")
        for reason in reasons:
            print(f"    - {reason}")
        print("\n  è¡ŒåŠ¨é¡¹:")
        print("    1. åœ¨æµ‹è¯•ç¯å¢ƒéƒ¨ç½²MySQL")
        print("    2. éªŒè¯åº”ç”¨å…¼å®¹æ€§")
        print("    3. å‡†å¤‡æ•°æ®è¿ç§»è„šæœ¬")
    elif migration_score >= 20:
        print("  ğŸŸ¢ å»ºè®®: ç»§ç»­ä½¿ç”¨SQLiteï¼Œä½†éœ€è¦ç›‘æ§")
        print("  ç†ç”±:")
        for reason in reasons:
            print(f"    - {reason}")
        print("\n  è¡ŒåŠ¨é¡¹:")
        print("    1. æ‰§è¡ŒSQLiteç´¢å¼•ä¼˜åŒ–")
        print("    2. å»ºç«‹å®šæœŸç›‘æ§")
        print("    3. å‡†å¤‡è¿ç§»é¢„æ¡ˆ")
    else:
        print("  ğŸŸ¢ å»ºè®®: ç»§ç»­ä½¿ç”¨SQLite")
        print("  å½“å‰çŠ¶æ€: SQLiteå®Œå…¨æ»¡è¶³éœ€æ±‚")
        print("\n  è¡ŒåŠ¨é¡¹:")
        print("    1. æ‰§è¡ŒSQLiteç´¢å¼•ä¼˜åŒ–")
        print("    2. æ¯æœˆè¿è¡Œä¸€æ¬¡ç›‘æ§")
    
    # 7. ä¼˜åŒ–å»ºè®®
    print("\nã€7ã€‘SQLiteä¼˜åŒ–å»ºè®®")
    print("-" * 80)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç´¢å¼•
    cursor = conn.cursor()
    cursor.execute("SELECT COUNT(*) FROM sqlite_master WHERE type='index' AND name NOT LIKE 'sqlite_%'")
    index_count = cursor.fetchone()[0]
    
    if index_count < 20:
        print("  âš ï¸  æ£€æµ‹åˆ°ç´¢å¼•æ•°é‡è¾ƒå°‘ï¼Œå»ºè®®æ‰§è¡Œç´¢å¼•ä¼˜åŒ–")
        print("     è¿è¡Œ: python optimize_database.py indexes")
    else:
        print("  âœ… ç´¢å¼•é…ç½®è‰¯å¥½")
    
    # æ£€æŸ¥VACUUM
    cursor.execute("PRAGMA page_count")
    page_count = cursor.fetchone()[0]
    cursor.execute("PRAGMA freelist_count")
    freelist_count = cursor.fetchone()[0]
    
    if freelist_count > page_count * 0.1:
        print("  âš ï¸  æ£€æµ‹åˆ°è¾ƒå¤šç¢ç‰‡ï¼Œå»ºè®®æ‰§è¡ŒVACUUM")
        print("     è¿è¡Œ: python optimize_database.py vacuum")
    else:
        print("  âœ… æ•°æ®åº“ç¢ç‰‡è¾ƒå°‘")
    
    conn.close()
    
    print("\n" + "=" * 80)
    print("ç›‘æ§å®Œæˆ")
    print("=" * 80)

if __name__ == '__main__':
    generate_report()

